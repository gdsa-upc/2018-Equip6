{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os \n",
    "import glob\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpli\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from keras import optimizers, callbacks\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Flatten, Dense \n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "from mlflow import log_metric, log_param, log_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = ['mercat_independencia','societat_general','desconegut','farmacia_albinyana','ajuntament','mnactec',\n",
    "         'escola_enginyeria','masia_freixa','castell_cartoixa','dona_treballadora','catedral',\n",
    "         'teatre_principal','estacio_nord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, mode='vgg16'):\n",
    "\n",
    "    if(mode=='vgg16'):\n",
    "        img = img.astype(np.float16)\n",
    "        img[:, :, 0] -= 103.939\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 123.68\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_file, img_reshape_size):\n",
    "\n",
    "    img = cv2.imread(img_file)\n",
    "    img = cv2.resize(img, img_reshape_size)\n",
    "    img = preprocess_image(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset(dataset_dir, img_reshape_size, nprocs=10):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    # Train dataset\n",
    "    for i in range(13):\n",
    "        path = os.path.join(dataset_dir,lista[i],'*.jpg')\n",
    "        files = glob.glob(path)\n",
    "\n",
    "        X.extend(Parallel(n_jobs=nprocs)(delayed(load_image)(im_file, img_reshape_size) for im_file in files))\n",
    "        y.extend([i]*len(files))\n",
    "        print('folder classifier/training/'+str(lista[i]), 'loaded')\n",
    "\n",
    "    X = np.asarray(X, dtype=np.float16)\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_val_dataset(dataset_dir, img_reshape_size, nprocs=10):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    # validation dataset\n",
    "    for i in range(13):\n",
    "        path = os.path.join(dataset_dir,lista[i],'*.jpg')\n",
    "        files = glob.glob(path)\n",
    "\n",
    "        X.extend(Parallel(n_jobs=nprocs)(delayed(load_image)(im_file, img_reshape_size) for im_file in files))\n",
    "        y.extend([i]*len(files))\n",
    "        print('folder classifier/validation/'+str(lista[i]), 'loaded')\n",
    "\n",
    "    X = np.asarray(X, dtype=np.float16)\n",
    "    y = np.asarray(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset train...\n",
      "('folder classifier/training/mercat_independencia', 'loaded')\n",
      "('folder classifier/training/societat_general', 'loaded')\n",
      "('folder classifier/training/desconegut', 'loaded')\n",
      "('folder classifier/training/farmacia_albinyana', 'loaded')\n",
      "('folder classifier/training/ajuntament', 'loaded')\n",
      "('folder classifier/training/mnactec', 'loaded')\n",
      "('folder classifier/training/escola_enginyeria', 'loaded')\n",
      "('folder classifier/training/masia_freixa', 'loaded')\n",
      "('folder classifier/training/castell_cartoixa', 'loaded')\n",
      "('folder classifier/training/dona_treballadora', 'loaded')\n",
      "('folder classifier/training/catedral', 'loaded')\n",
      "('folder classifier/training/teatre_principal', 'loaded')\n",
      "('folder classifier/training/estacio_nord', 'loaded')\n",
      "Loading dataset validation...\n",
      "('folder classifier/validation/mercat_independencia', 'loaded')\n",
      "('folder classifier/validation/societat_general', 'loaded')\n",
      "('folder classifier/validation/desconegut', 'loaded')\n",
      "('folder classifier/validation/farmacia_albinyana', 'loaded')\n",
      "('folder classifier/validation/ajuntament', 'loaded')\n",
      "('folder classifier/validation/mnactec', 'loaded')\n",
      "('folder classifier/validation/escola_enginyeria', 'loaded')\n",
      "('folder classifier/validation/masia_freixa', 'loaded')\n",
      "('folder classifier/validation/castell_cartoixa', 'loaded')\n",
      "('folder classifier/validation/dona_treballadora', 'loaded')\n",
      "('folder classifier/validation/catedral', 'loaded')\n",
      "('folder classifier/validation/teatre_principal', 'loaded')\n",
      "('folder classifier/validation/estacio_nord', 'loaded')\n",
      "('X_train shape:', (1194, 224, 224, 3))\n",
      "('y_train shape:', (1194, 13))\n",
      "('X_val shape:', (477, 224, 224, 3))\n",
      "('y_val shape:', (477, 13))\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "mypredictions (Dense)        (None, 13)                53261     \n",
      "=================================================================\n",
      "Total params: 134,313,805\n",
      "Trainable params: 134,313,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(<keras.engine.input_layer.InputLayer object at 0x7fe1a8f02810>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8f02c10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8dfa190>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fe1a8dfab10>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8e014d0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1da9b2690>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fe1a8dea290>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8f07510>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8f13510>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8e4b310>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fe1a8d2e210>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8e7ff50>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1a8f0f450>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1d3fdd610>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fe1d3fec7d0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1d3ff8650>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1d3f95ed0>, False)\n",
      "(<keras.layers.convolutional.Conv2D object at 0x7fe1d3f956d0>, False)\n",
      "(<keras.layers.pooling.MaxPooling2D object at 0x7fe1d3fb1dd0>, False)\n",
      "(<keras.layers.core.Flatten object at 0x7fe1d3f40210>, False)\n",
      "(<keras.layers.core.Dense object at 0x7fe1d3f40b10>, True)\n",
      "(<keras.layers.core.Dense object at 0x7fe1d3f5db10>, True)\n",
      "(<keras.layers.core.Dense object at 0x7fe1d3f08fd0>, True)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "mypredictions (Dense)        (None, 13)                53261     \n",
      "=================================================================\n",
      "Total params: 134,313,805\n",
      "Trainable params: 119,599,117\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "11/11 [==============================] - 24s 2s/step - loss: 4.3000 - acc: 0.1191 - val_loss: 2.5556 - val_acc: 0.1040\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 18s 2s/step - loss: 2.5763 - acc: 0.0456 - val_loss: 2.2301 - val_acc: 0.1940\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 2.5228 - acc: 0.2201 - val_loss: 2.4709 - val_acc: 0.3036\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 18s 2s/step - loss: 2.3392 - acc: 0.2437 - val_loss: 1.3840 - val_acc: 0.4660\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 1.9826 - acc: 0.3374 - val_loss: 1.5638 - val_acc: 0.3077\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 18s 2s/step - loss: 1.4769 - acc: 0.5057 - val_loss: 0.7774 - val_acc: 0.8220\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 1.2263 - acc: 0.5967 - val_loss: 0.5497 - val_acc: 0.8540\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 17s 2s/step - loss: 0.8666 - acc: 0.7205 - val_loss: 0.6049 - val_acc: 0.9231\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.5686 - acc: 0.8503 - val_loss: 0.2749 - val_acc: 0.9540\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 18s 2s/step - loss: 0.3514 - acc: 0.9295 - val_loss: 0.1844 - val_acc: 0.9858\n",
      "('File', 'VGG16_lr0.0001_train3_epochs10_data_augTrue.h5', 'saved')\n"
     ]
    }
   ],
   "source": [
    "def create_VGG16_model(n_classes=13, n_layers_train=2, learning_rate=0.0001):\n",
    "\n",
    "\n",
    "    vgg16_base = vgg16.VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))    \n",
    "\n",
    "\n",
    "    fc2 = vgg16_base.get_layer('fc2').output\n",
    "    mypredictions = Dense(n_classes, activation='softmax', name='mypredictions')(fc2)\n",
    "    model = Model(inputs=vgg16_base.input, outputs=mypredictions)\n",
    "    \n",
    "    model.summary()\n",
    "    # Freeze the layers except the last n_layers_train layers\n",
    "    for layer in model.layers[:-n_layers_train]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[:]:\n",
    "        print(layer, layer.trainable)    \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.Adam(lr=learning_rate),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "class LogMlFlowMetrics(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        log_metric(\"train_loss\", logs.get('loss'))\n",
    "        log_metric(\"train_acc\", logs.get('acc'))\n",
    "        log_metric(\"val_loss\", logs.get('val_loss'))\n",
    "        log_metric(\"val_acc\", logs.get('val_acc'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    batch_size = 100\n",
    "    n_epoch = 10\n",
    "    learning_rate = 0.0001\n",
    "    n_layers_train = 3\n",
    "    data_augmentation = True\n",
    "    \n",
    "\n",
    "    log_param(\"batch_size\", batch_size)\n",
    "    log_param(\"n_epoch\", n_epoch)\n",
    "    log_param(\"learning_rate\", learning_rate)\n",
    "    log_param(\"n_layers_train\", n_layers_train)\n",
    "    log_param(\"data_augmentation\", data_augmentation)\n",
    "\n",
    "\n",
    "    img_reshape_size = (224,224)\n",
    "\n",
    "\n",
    "    dataset_dir_train = os.path.join('classifier','training')\n",
    "    dataset_dir_val = os.path.join('classifier','validation')\n",
    "\n",
    "\n",
    "    print('Loading dataset train...')\n",
    "    X_train, y_train = load_train_dataset(dataset_dir_train, img_reshape_size) \n",
    "    print('Loading dataset validation...')\n",
    "\n",
    "    X_val, y_val = load_val_dataset(dataset_dir_val, img_reshape_size)\n",
    "    \n",
    "\n",
    "\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_val = to_categorical(y_val)\n",
    "\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print('y_train shape:', y_train.shape)#\n",
    "    print('X_val shape:', X_val.shape)\n",
    "    print('y_val shape:', y_val.shape)\n",
    "\n",
    "\n",
    "    if(data_augmentation==True):\n",
    "        train_datagen = image.ImageDataGenerator(\n",
    "                                                width_shift_range=0.1,\n",
    "                                                height_shift_range=0.1,\n",
    "                                                shear_range=0.1,\n",
    "                                                rotation_range=8,\n",
    "                                                fill_mode='nearest'\n",
    "                                                )\n",
    "        val_datagen = image.ImageDataGenerator()\n",
    "    else:\n",
    "        train_datagen = image.ImageDataGenerator()\n",
    "        val_datagen = image.ImageDataGenerator()\n",
    "\n",
    "    train_generator = train_datagen.flow(x=X_train, y=y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                seed=42)\n",
    "    val_generator = train_datagen.flow(x=X_train, y=y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                seed=42)\n",
    "    \n",
    "\n",
    "    model = create_VGG16_model(n_layers_train=n_layers_train, learning_rate=learning_rate)\n",
    "    \n",
    "\n",
    "    tensorboard_log_dir='VGG16_lr'+str(learning_rate)+'_train'+str(n_layers_train)+'_epochs'+str(n_epoch)+'_data_aug'+str(data_augmentation)\n",
    "\n",
    "    tb_callback = callbacks.TensorBoard(log_dir=os.path.join('Graph', tensorboard_log_dir),\n",
    "                                       histogram_freq=0, \n",
    "                                       write_graph=True, \n",
    "                                       write_images=False)\n",
    "\n",
    "    earlystop = callbacks.EarlyStopping(monitor='val_loss', patience=2, \\\n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "    mlflow_callback = LogMlFlowMetrics()\n",
    "    \n",
    "\n",
    "    model_history = model.fit_generator(train_generator,\n",
    "                                        validation_data=val_generator,\n",
    "                                        validation_steps=5,\n",
    "                                        shuffle=True,\n",
    "                                        epochs=n_epoch,\n",
    "                                        steps_per_epoch=np.ceil(X_train.shape[0]//batch_size),\n",
    "                                        callbacks=[tb_callback, earlystop, mlflow_callback],\n",
    "                                        verbose=1,\n",
    "                                        use_multiprocessing=True)\n",
    "    \n",
    "\n",
    "    if not os.path.isdir('Model'):\n",
    "        os.mkdir('Model')\n",
    "    filename = 'VGG16_lr'+str(learning_rate)+'_train'+str(n_layers_train)+'_epochs'+str(n_epoch)+'_data_aug'+str(data_augmentation)+'.h5'\n",
    "\n",
    "    model_file = os.path.join('Model', filename)\n",
    "    model.save(model_file)\n",
    "    log_artifact(model_file)\n",
    "    print('File', filename, 'saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
