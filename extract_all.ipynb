{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "from params import get_params\n",
    "from sklearn import preprocessing\n",
    "import sklearn.preprocessing\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['split'] = 'val'\n",
    "readfile = os.path.join(params['root'],params['root_save'], params['image_lists'],params['split'] + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(readfile,'r') as f:\n",
    "        image_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for image_name in image_list:\n",
    "\n",
    "        # Read image\n",
    "        lista.append(os.path.join(params['root'],params['database'],\n",
    "                                     params['split'],\n",
    "                                     'images',image_name.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "imagen = []\n",
    "final = []\n",
    "for i in range(len(image_list)):   \n",
    "    imagen.append(image.load_img(lista[i], target_size=(224, 224)))\n",
    "    final.append(image.img_to_array(imagen[i]))\n",
    "    final[i] = np.expand_dims(final[i], axis=0)\n",
    "    final[i] = preprocess_input(final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida = []\n",
    "k = 0\n",
    "for k in range(len(image_list)):\n",
    "    salida.append(model.predict(final[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['splitt'] = 'test'\n",
    "readfile2 = os.path.join(params['root'],params['root_save'], params['image_lists'],params['splitt'] + '.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(readfile2,'r') as f2:\n",
    "    image_list2 = f2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista2 = []\n",
    "for image_name2 in image_list2:\n",
    "    lista2.append(os.path.join(params['root'],params['database'],\n",
    "                                     params['splitt'],\n",
    "                                     'images',image_name2.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2=0\n",
    "imagen2 = []\n",
    "final2 = []\n",
    "for i2 in range(len(image_list2)):   \n",
    "    imagen2.append(image.load_img(lista2[i2], target_size=(224, 224)))\n",
    "    final2.append(image.img_to_array(imagen2[i2]))\n",
    "    final2[i2] = np.expand_dims(final2[i2], axis=0)\n",
    "    final2[i2] = preprocess_input(final2[i2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida2 = []\n",
    "k2 = 0\n",
    "for k2 in range(len(image_list2)):\n",
    "    salida2.append(model.predict(final2[k2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['splittr'] = 'train'\n",
    "readfile3 = os.path.join(params['root'],params['root_save'], params['image_lists'],params['splittr'] + '.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(readfile3,'r') as f3:\n",
    "    image_list3 = f3.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista3 = []\n",
    "for image_name3 in image_list3:\n",
    "    lista3.append(os.path.join(params['root'],params['database'],\n",
    "                                     params['splittr'],\n",
    "                                     'images',image_name3.rstrip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i3=0\n",
    "imagen3 = []\n",
    "final3 = []\n",
    "for i3 in range(len(image_list3)):   \n",
    "    imagen3.append(image.load_img(lista3[i3], target_size=(224, 224)))\n",
    "    final3.append(image.img_to_array(imagen3[i3]))\n",
    "    final3[i3] = np.expand_dims(final3[i3], axis=0)\n",
    "    final3[i3] = preprocess_input(final3[i3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida3 = []\n",
    "k3 = 0\n",
    "for k3 in range(len(image_list3)):\n",
    "    salida3.append(model.predict(final3[k3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_val = np.asarray(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(descriptors_val, open(\"save_val.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imagen, open(\"save_img.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_test = np.asarray(salida2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(descriptors_test, open(\"save_test.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imagen2, open(\"save_img2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_train = np.asarray(salida3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(descriptors_train, open(\"save_train.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(imagen3, open(\"save_img3.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
